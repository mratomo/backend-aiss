# Integración de Attack Vulnerability Service con LLM

## Visión General

El Attack Vulnerability Service utiliza modelos de lenguaje (LLM) a través del protocolo MCP (Model Context Protocol) para contextualizar y enriquecer el análisis de vulnerabilidades basado en MITRE ATT&CK. Esta integración permite proporcionar explicaciones claras y recomendaciones personalizadas sobre vulnerabilidades detectadas durante sesiones SSH.

## Arquitectura de Integración

```
┌────────────────┐     ┌────────────────┐     ┌────────────────┐
│                │     │                │     │                │
│ Terminal       │────▶│ Attack Vulne-  │────▶│ MCP-compatible │
│ Gateway        │     │ rability Svc   │     │ LLM Provider   │
└────────────────┘     └────────────────┘     └───────┬────────┘
                              │                       │
                              │                       │
                              ▼                       ▼
                       ┌────────────────┐     ┌────────────────┐
                       │                │     │                │
                       │ MITRE ATT&CK   │     │ LLM Model      │
                       │ Database       │     │ (Ollama/Cloud) │
                       └────────────────┘     └────────────────┘
```

Esta arquitectura permite una separación clara de responsabilidades, donde:
- El Terminal Gateway detecta software y sistemas operativos
- El Attack Vulnerability Service identifica vulnerabilidades usando MITRE ATT&CK
- El proveedor LLM compatible con MCP (Ollama, OpenAI, Anthropic, etc.) proporciona contexto adicional

## Características de la Integración

- **Independencia del proveedor**: Funciona con cualquier LLM compatible con el protocolo MCP
- **Contextualización inteligente**: Transforma datos técnicos en explicaciones comprensibles
- **Adaptación al entorno**: Personaliza recomendaciones según el contexto del sistema
- **Análisis profundo**: Correlaciona vulnerabilidades con tácticas y técnicas MITRE ATT&CK
- **Priorización basada en contexto**: Ordena vulnerabilidades según su relevancia real

## Flujo de Trabajo

1. Terminal Gateway detecta información del sistema durante una sesión SSH
2. Attack Vulnerability Service identifica vulnerabilidades potenciales basadas en MITRE ATT&CK
3. Los datos técnicos de vulnerabilidades se envían al servicio MCP de LLM
4. El LLM analiza los datos y proporciona:
   - Explicaciones claras en lenguaje natural
   - Evaluación contextualizada del riesgo
   - Recomendaciones personalizadas de mitigación
   - Priorización basada en el entorno específico
5. Las respuestas enriquecidas se devuelven al usuario a través del Terminal Gateway

## Configuración de Integración LLM

```
# Configuración de LLM en Attack Vulnerability Service
LLM_PROVIDER_URL=http://rag-agent:8080/api/v1/llm
LLM_PROVIDER_TYPE=mcp
LLM_MAX_TOKENS=1024
LLM_TEMPERATURE=0.3
LLM_SYSTEM_PROMPT_TEMPLATE=/app/templates/vulnerability_system_prompt.txt
```

## Prompts para Análisis de Vulnerabilidades

El Attack Vulnerability Service utiliza plantillas de prompts específicas para diferentes tareas de análisis. A continuación, se muestran ejemplos:

### Evaluación de Vulnerabilidad

```
Actúa como un experto en ciberseguridad analizando la siguiente vulnerabilidad:

Vulnerabilidad: {vulnerability_id}
Software afectado: {software_name} {software_version}
Descripción técnica: {description}
Técnicas MITRE: {mitre_techniques}

Sistema:
OS: {os_name} {os_version}
Rol: {system_role}
Software adicional: {additional_software}

Proporciona:
1. Una explicación clara del riesgo en términos comprensibles para no expertos
2. El impacto potencial en este sistema específico
3. Recomendaciones concretas de mitigación
4. Nivel de prioridad para corregir esta vulnerabilidad (Alto/Medio/Bajo)
```

### Resumen de Análisis

```
Crea un resumen conciso de las siguientes vulnerabilidades detectadas:

Sistema: {os_name} {os_version}
Vulnerabilidades detectadas: {vulnerability_count}

Resumen de vulnerabilidades:
{vulnerability_list}

Proporciona:
1. Un párrafo breve explicando la situación general de seguridad
2. Las 3 vulnerabilidades más críticas que deben abordarse primero
3. Una recomendación general sobre cómo mejorar la seguridad del sistema
```

## Beneficios de la Integración LLM

1. **Explicaciones claras**: Convierte información técnica compleja en explicaciones comprensibles
2. **Contextualización**: Adapta el análisis al entorno específico del sistema
3. **Priorización inteligente**: Ayuda a enfocarse en las vulnerabilidades más relevantes
4. **Mitigación específica**: Proporciona recomendaciones adaptadas al entorno concreto
5. **Reducción de falsos positivos**: Filtra vulnerabilidades que no son aplicables al contexto

## Ejemplos de Respuestas

### Ejemplo de Análisis de Vulnerabilidad

```json
{
  "vulnerability_id": "CVE-2022-12345",
  "explanation": "Esta vulnerabilidad permite a un atacante remoto obtener acceso no autorizado al servidor SSH. En términos sencillos, es como si alguien pudiera entrar por una puerta trasera sin tener la llave correcta.",
  "contextual_impact": "En este servidor web de producción, un atacante podría acceder a archivos confidenciales, modificar el sitio web o instalar malware. Es especialmente crítico porque el servidor es accesible desde Internet y contiene datos sensibles.",
  "recommendations": [
    "Actualizar OpenSSH a la versión 8.0 o superior inmediatamente",
    "Implementar autenticación de múltiples factores para todos los usuarios",
    "Limitar los accesos SSH solo a IPs específicas a través de reglas de firewall"
  ],
  "priority": "Alto",
  "reasoning": "La combinación de esta vulnerabilidad con un servidor web expuesto a Internet representa un riesgo crítico que debe mitigarse de inmediato."
}
```

### Ejemplo de Resumen de Vulnerabilidades

```json
{
  "summary": "El sistema Ubuntu 20.04 LTS muestra 12 vulnerabilidades potenciales, 3 de alta severidad. La mayoría están relacionadas con software desactualizado, especialmente OpenSSH y Apache. El nivel general de riesgo es ELEVADO y requiere atención inmediata.",
  "critical_vulnerabilities": [
    {
      "id": "CVE-2022-12345",
      "summary": "Bypass de autenticación en OpenSSH 7.6p1",
      "priority": "Inmediata"
    },
    {
      "id": "CVE-2021-56789",
      "summary": "Ejecución remota de código en Apache 2.4.29",
      "priority": "Inmediata"
    },
    {
      "id": "CVE-2023-98765",
      "summary": "Elevación de privilegios en kernel Linux 5.4.0",
      "priority": "Alta"
    }
  ],
  "general_recommendation": "Se recomienda actualizar urgentemente los paquetes de OpenSSH y Apache. Además, debe implementarse un programa regular de actualizaciones de seguridad y considerar la implementación de autenticación de múltiples factores para todos los servicios críticos."
}
```

## Consideraciones de Implementación

- **Proveedores LLM**: La integración funciona con cualquier proveedor compatible con MCP:
  - Modelos locales a través de Ollama MCP Server
  - Servicios en la nube como OpenAI, Anthropic, etc.
  - Modelos propios alojados en infraestructura privada
  
- **Privacidad**: Al utilizar LLMs locales, se garantiza que la información sensible de vulnerabilidades no salga de la infraestructura interna

- **Rendimiento**: El análisis contextual mediante LLM añade latencia al proceso de detección, por lo que se recomienda:
  - Realizar análisis en segundo plano
  - Implementar caché para respuestas similares
  - Priorizar la detección rápida de vulnerabilidades críticas

- **Precisión**: La calidad del análisis contextual depende de:
  - La capacidad del LLM utilizado
  - La calidad de los prompts de ingeniería
  - La precisión de los datos de MITRE ATT&CK

## Referencias

- [Model Context Protocol Specification](https://github.com/anthropics/mcp)
- [MITRE ATT&CK Framework](https://attack.mitre.org/)
- [attackcti Python Client](https://github.com/swimlane/pyattck)
- [CVE Database](https://cve.mitre.org/)
- [National Vulnerability Database](https://nvd.nist.gov/)